# Homework 14
## 2. Document the microservice architeture and components/tools/dependencies
![Microservice architecture](./hw14_1.png)
API gateway: route request to the corrsponding services;

Eureka: service registry, monitor service health, auto-register new services, service discovery

How to communicate between services: use restTemplate

Load balancing: enables the service to scale well and stay high availability when the traffic load increases.

circuit breaker: a server calls b and b has a problem, circuit breaker can catch the problem and process a fallback plan.

Configuration: spring cloud offers support for Consul as a server for configurations. We can use applications.properties.

Kafka: can be used for communication between services. It can decouple the data streams and systems.

## 3. What are resilience pattern? What is circuit breaker?
Resilience pattern are design principles and techniques used to build robust and resilient software that can handle failures and disrupts;

Retry: Retry pattern involves automatically retrying a failed operation with the hope that it will succeed on subsequent attempts. It allows for transient failures to be overcome without manual intervention.

Circuit Breaker: Circuit Breaker pattern is used to prevent a system from continuously executing a failing operation. It monitors the availability of a service and, if the failure rate exceeds a certain threshold, the circuit breaker trips, blocking subsequent requests and providing fallback responses.

Bulkhead: Bulkhead pattern is about dividing the system into isolated compartments (or "bulkheads") to limit the impact of failures. If one component fails, it does not bring down the entire system but only affects a specific portion.

Timeout: Timeout pattern involves setting a maximum time for an operation to complete. If the operation exceeds the defined time limit, it is considered failed or abandoned. Timeouts prevent requests from waiting indefinitely and help maintain system responsiveness.

Fallback: Fallback pattern defines an alternative response or behavior when an operation fails. It allows the system to gracefully handle failures by providing a backup plan or default behavior.

Circuit Breaking: Circuit Breaking pattern is similar to the Circuit Breaker pattern but focuses on detecting and breaking communication with external services or dependencies that are experiencing issues. It helps prevent cascading failures by isolating the failing service.

Retry with Backoff: Retry with Backoff pattern introduces a delay between retry attempts, gradually increasing the delay with subsequent retries. It helps avoid overloading the system and reduces the chances of immediate consecutive failures.

Time out: a time out prevents a microservice from waiting too long for another microservice;

Circuit breaker: if a system call results in an error, the circuit breaker is opened and does not allow any calls to pass through.

## 4. Read this article, then list the important questions, then write your answers
### What issues are generally solved by spring clouds?
The following problems can be solved with spring cloud:   

Complicated issues caused by distributed systems: This includes network issues, latency problems, bandwidth problems, and security issues. 

Service Discovery issues: Service discovery allows processes and services to communicate and locate each other within a cluster. 

Redundancy issues: Distributed systems can often have redundancy issues. 

Load balancing issues: Optimize the distribution of workloads among multiple computing resources, including computer clusters, central processing units, and network links. 

Reduces performance issues: Reduces performance issues caused by various operational overheads.

### What do you mean by Bounded Context?
A Bounded Context is a central pattern in DDD (Domain-Driven Design), which deals with collaboration across large models and teams. DDD breaks large models down into multiple contexts to make them more manageable. Additionally, it explains their relationship explicitly. The concept promotes an object-oriented approach to developing services bound to a data model and is also responsible for ensuring the integrity and mutability of said data model. 

### What do you mean by Domain driven design?
DDD (Domain-Driven-Design) is basically an architectural style that is based on Object-Oriented Analysis Design approaches and principles. In this approach, the business domain is modeled carefully in software, without regard to how the system actually works. By interconnecting related components of the software system into a continuously evolving system, it facilitates the development of complex systems. There are three fundamental principles underlying it as shown below: 

Concentrate on the core domain and domain logic. 
Analyze domain models to find complex designs. 
Engage in regular collaboration with the domain experts to improve the application model and address emerging domain issues. 

## 5. how to do load balance in microservice? Write a long Summary by yourself.
Withour load balance, single point server and overloaded servers may occur.

A load balancer minimize server response time and maximize throuput. Ensure high availability and reliability by sending requests to online servers. Load balancer will check the health status of servers and monitor the capabilities of handling requests and will add or remove server depending on the requests.

Load is usually put between client and web front end server, between application servers, cache servers and front end servers, between cache servers and database servers.

Different categories of lb
1. Layer 4: decision is made on based on the TCP/UDP ports that packets use along with source and destination IP address. This category of bl maximizes the utilization and availability by distributing the traffic IP addresses;
2. Layer 7: adds content switching to load balancing and it uses information such as  HTTP header, cookies, uniform resource identifier, SSL session ID, and HTML form data to decide the routing request across the servers. Content switching in a Layer 7 load balancer refers to the capability of routing incoming network traffic based on specific content or characteristics of the data payload.
3. global server lb: extends the capability of L4 and L7 servers in different geographic locations and distributes a large amount of traffic across multiple data centers efficiently. It also ensures a consistent experience for end-users when they are navigating multiple applications and services in a digital workspace. 

Different algorithm
1. round robin;
2. weighted round robin;
3. least connection method;
4. least repsonse time method: fewest active connections and the least average response time.
5. source ip hash;

In system design:
Enables elsatic scalability and improve performance and throughput. improve performance and fault tolerant. Load balancers can be placed at any software layer.

## 6. How to do service discovery?
Use Eureka server, it help to register service, check the heartbeat. For sychronous coomunication, microservices have to find out at which port or IP  address other microservices can be accessed.

## 7. What are the major components of Kafka?
Producers: send data to kafka;

Brokers: server, can have different topics and its corresponding partitions;

CLuster: several brokers;

Consumers: get data from kafka;

Topics: Topics are the fundamental units of data organization in Kafka. They represent the streams of records or messages that are published and consumed by producers and consumers, respectively. Topics are partitioned and can be replicated across multiple brokers for fault tolerance.

Producers: Producers are responsible for publishing messages to Kafka topics. They write data to topics and can choose to specify the target partition or rely on Kafka's partitioning strategy. Producers can also set message keys for message ordering and facilitate efficient data distribution.

Consumers: Consumers read and process messages from Kafka topics. They subscribe to one or more topics and consume messages from the assigned partitions. Consumers can be part of a consumer group, where each consumer in the group processes a subset of partitions for parallel processing.

Brokers: Brokers are the Kafka servers that form the distributed cluster. They store and manage the published messages in topics, handle consumer requests for messages, and replicate data across brokers for fault tolerance. Brokers are responsible for the storage, retrieval, and replication of Kafka data.

ZooKeeper: ZooKeeper is a centralized coordination service used by Kafka for cluster management, leader election, and maintaining metadata. It tracks the status of brokers, topics, partitions, and consumer groups. Starting from Apache Kafka 2.8.0, ZooKeeper is no longer required, and Kafka uses its internal metadata quorum for coordination.

## 8. What do you mean by a Partition in Kafka?
A partition is a fundamental unit of a topic, each data from the same topic with the same hashcode of the key can be put into the same partition. 

Each partition is hosted on a specific broker and multiple replicas store in other broker. 

1. Ordering: the order is maintained in each partition, the one with lower offsets will be consumed before higher offsets
2. Scalability, fault tolerance: several replicas allows multiple read;
3. Data retention: Each partition has its own configurable retention period, specifying how long the messages within the partition should be retained. Once the retention period is exceeded, older messages are eligible for deletion.


## 9. What do you mean by zookeeper in Kafka and what are its uses?
In the context of Kafka, zookeeper is used to store metadata of topics, brokers, partitions, leader election, cluster coordination. 

ZooKeeper is a crucial component that is used for coordination and management tasks. Kafka relies on ZooKeeper for various functions, including:

Metadata Management: ZooKeeper stores and maintains important metadata about the Kafka cluster, such as the list of Kafka brokers, topic configurations, partition assignments, and consumer group information. This metadata is critical for Kafka's operation and helps ensure the availability, consistency, and reliability of the cluster.

Leader Election: ZooKeeper plays a significant role in leader election for Kafka partitions. Each partition in Kafka has one broker designated as the leader responsible for handling read and write requests, while the other brokers act as followers. ZooKeeper helps in coordinating and electing the leader for each partition, ensuring that only one broker is actively serving as the leader at any given time.

Cluster Membership: Kafka brokers register themselves with ZooKeeper, creating ephemeral znodes (temporary nodes) to indicate their presence and availability. ZooKeeper helps in maintaining an up-to-date list of active brokers in the cluster. This information is vital for discovering and connecting to the Kafka brokers.

Watchers and Notifications: ZooKeeper allows Kafka to set up watches on znodes. Kafka can register a watcher on a specific znode to receive notifications about changes to that znode. This mechanism enables Kafka to be notified of any changes in the cluster's state or metadata, such as the addition or removal of brokers or topics

## 10. Can we use Kafka without Zookeeper?
Yes.

## 11. Explain the concept of Leader and Follower in Kafka.
Leader in kafka represents the leader partition which receives the data from the producer; Each partition in Kafka has one broker designated as the leader for that partition. The leader is responsible for handling all read and write requests for the partition. Clients, including producers and consumers, interact with the leader to publish and consume messages.

Followers are the replication of the leader and partition and will have the data sychronized and can be used for read data from consumers. Follower brokers replicate the data from the leader for a particular partition. They act as passive replicas that maintain an identical copy of the leader's data. 

## 12. Why is Topic Replication important in Kafka? What do you mean by ISR in Kafka?
Enbale fault tolerance, data durability, higher read ability. 

ISR -> in-sync replicas which means once the data is write to the leader, it will also sync to its replcas.

## 13. What do you understand about a consumer group in Kafka?
Consumer group is consists of one or more consumers. Each consumer group subscribe to multiple topics and each consumer in it read from exclusive partitions of same topic. Multiple consumers read on the same topic is acceptable. 

## 14. How do you start a Kafka server?
Start zookeeper first and then start a kafka broker.

## 15. Tell me about some of the real-world usages of Apache Kafka.
Real-time Stream Processing: Kafka is used for building real-time data pipelines and stream processing applications. It can ingest and process high volumes of data in real-time, allowing organizations to derive valuable insights, perform analytics, and make data-driven decisions as events occur.

Event Sourcing and CQRS: Kafka's log-based architecture makes it suitable for implementing event sourcing and Command Query Responsibility Segregation (CQRS) patterns. It allows capturing and storing all events as a log, which can be used for rebuilding state or auditing purposes.

Messaging System: Kafka serves as a reliable and scalable messaging system that decouples producers and consumers. It enables asynchronous communication between various components and services within a distributed system, facilitating loose coupling and scalability.

Log Aggregation: Kafka can be used for centralized log aggregation, where log messages from multiple sources are collected and stored in a central location. This helps in efficient log analysis, troubleshooting, and monitoring of distributed systems.

Data Integration and ETL: Kafka acts as a central data hub for integrating and exchanging data between different systems and applications. It can be used in Extract, Transform, Load (ETL) processes, where data is sourced from various systems, transformed, and loaded into target systems or data warehouses.

Metrics and Monitoring: Kafka can be used to collect and process metrics and monitoring data from various sources. It provides a reliable and scalable platform for handling high-volume, time-series data generated by applications and infrastructure components.

Internet of Things (IoT): Kafka is used in IoT applications for handling large volumes of real-time data generated by sensors, devices, and edge computing systems. It enables data ingestion, processing, and analytics on IoT data streams.

Microservices Communication: Kafka facilitates communication and data exchange between microservices in a distributed microservices architecture. It enables asynchronous, event-driven communication, ensuring loose coupling and scalability of microservices.

## 16. Describe partitioning key in Kafka.
It helps to identify which partition the message belongs to. (targetPartiton = Math.abs(Utils.murmur2(keyBytes)) % (partitionNum - 1) The message with the same key will be send to the same partition.

## 17. What is the purpose of partitions in Kafka?
Improve proficiency and throughput. Allows linear scalling for producers and consumers. Kafka scales to support multiple consumers and producers simultaneously.

## 18. Differentiate between Rabbitmq and Kafka.
| Parameter | RabbitMQ | Kafka |
|---|----|-----|
|Performance | 10k message per sec | 1M per sec|
|Data type| Transactional | Operational|
| Type | Push based | Pull based|
|Data type | distinct bounded data | unbounded continuous data|

RabbitMQ is better for applications where the architecture of the application is unknown, and it develops and evolves with the problem statement and the solution. RabbitMQ is much more flexible and easy to use in these circumstances as compared to Kafka. But once the application matures and there is a requirement for scaling, large throughput, reliability, robustness, and replayability of messages, then RabbitMQ becomes a bottleneck, and itâ€™s better to switch to Kafka.

## 19. What are the guarantees that Kafka provides?
At most once guarantee: The producer will send messages at most one time, and will not try sending them again if it receives an error or timeout message from the broker. This means that information will be lost if the consumer crashes before it has finished processing all the current messages on the topic.

At least once guarantee: The producer will send messages at least one time. If the producer receives an error or timeout message from the broker, then it will attempt to resend the message. This means that messages should never be lost, although the producer may duplicate work (which may also result in duplicate outputs).

Exact once: The message will be delivered exactly one time. Failures and retries may occur, but the consumer is guaranteed to only receive a given message once.

## 20. What do you mean by an unbalanced cluster in Kafka? How can you balance it?
An unbalanced cluster in Kafka refers to a situation where the distribution of partitions across the available brokers is uneven or skewed. In a balanced cluster, each broker in the Kafka cluster should have a roughly equal number of partitions assigned to it, ensuring that the workload is evenly distributed and the resources are effectively utilized.

Use automated tools: Kafka provides built-in tools like the partition reassignment tool (kafka-reassign-partitions.sh) and the preferred replica election tool (kafka-preferred-replica-election.sh). These tools help in redistributing partitions and electing preferred replicas to achieve a balanced cluster. You can use these tools to trigger partition reassignments and replica elections.

Adjust replication factor: Ensure that the replication factor for topics is appropriately set. Increasing the replication factor can distribute partitions across more brokers, reducing the load on individual brokers and achieving a more balanced cluster. However, keep in mind the trade-off between replication factor and storage requirements.

Monitor and analyze cluster health: Regularly monitor the cluster health and partition distribution using Kafka monitoring tools or third-party solutions. Identify any imbalances or hotspots in terms of partition distribution, broker utilization, or throughput. Analyze the metrics and logs to understand the root causes of the imbalance.

Adjust partition assignment algorithms: Kafka provides different partition assignment algorithms, such as the default range-based algorithm or custom assignment strategies. Evaluate and adjust the partition assignment algorithm based on your requirements and the characteristics of your workload. Some algorithms prioritize even distribution, while others consider factors like network proximity or data locality.

## 25. What is offset?
Offset is the id of each message within a partition.
